{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# packages used in this script         \n",
    "########################################\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: generate_feature_table()\n",
    "# Param:\n",
    "#     - path (str): the path to the general news data file(s).\n",
    "# Return:\n",
    "#     - None\n",
    "# Feature table is generated for the classification task\n",
    "################################################################################################################################\n",
    "\n",
    "def generate_feature_table(path):\n",
    "    # the generated feature table is saved in the folder \"ClassifyNews\", and the file name is \"NewEventTable_V1.csv\"\n",
    "    with open(\"ClassifyNews/NewEventTable_V1.csv\", \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',')\n",
    "        csv_writer.writerow(['id', 'company', 't1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', '1_month', '3_month', '6_month', '12_month'])\n",
    "\n",
    "        directory = path\n",
    "        for root,dirs,files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    try:\n",
    "                        print(file)\n",
    "                        data = pd.read_csv(directory + \"/\" + file, engine='python', error_bad_lines=False)\n",
    "                        data = data.to_numpy()\n",
    "\n",
    "                        event_date = (file.split(\".csv\")[0]).split('-')[-1]\n",
    "                        event_year = event_date[:4]\n",
    "                        event_month = event_date[4:6]\n",
    "                        event_day = event_date[6:8]\n",
    "                        new_event_date = str(event_year) + \"-\" + str(event_month) + \"-\" + str(event_day)\n",
    "\n",
    "                        company_name = file.split(\"_\")[0]\n",
    "\n",
    "                        for row in data:\n",
    "                            ids = row[0]\n",
    "                            available_text = True\n",
    "\n",
    "                            for i in range(len(row[1])-5):\n",
    "                                if row[1][i:i+5] == \"merge\":\n",
    "                                    available_text = False\n",
    "                                    break\n",
    "\n",
    "                                if row[1][i:i+5] == \"acqui\":\n",
    "                                    available_text = False\n",
    "                                    break\n",
    "\n",
    "                            if available_text == True:\n",
    "                                context = [row[1]]\n",
    "\n",
    "                                try:\n",
    "                                    soup = bs(row[1], \"html.parser\")\n",
    "                                    pub_date = soup.findAll('pubinfo:dates')[0]\n",
    "                                    pub_date_tag = pub_date('pubinfo:pubdate')[0]\n",
    "\n",
    "                                    day = pub_date_tag['day']\n",
    "                                    month = pub_date_tag['month']\n",
    "                                    year = pub_date_tag['year']\n",
    "\n",
    "                                    news_date = str(year) + \"-\" + str(month) + \"-\" + str(day)\n",
    "\n",
    "                                    delta_date = (datetime.strptime(new_event_date, '%Y-%m-%d') - datetime.strptime(news_date, '%Y-%m-%d')).days\n",
    "\n",
    "                                    df_temp = cv.transform(context)\n",
    "                                    prob = lda.transform(df_temp)\n",
    "\n",
    "                                    output_row = [ids, company_name]\n",
    "                                    for item in prob[0]:\n",
    "                                        output_row.append(item)\n",
    "\n",
    "                                    if delta_date < 30:\n",
    "                                        output_row.append(1)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        count_1 += 1\n",
    "                                    elif delta_date < 90:\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(1)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        count_3 += 1\n",
    "                                    elif delta_date < 180:\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(1)\n",
    "                                        output_row.append(0)\n",
    "                                        count_6 += 1\n",
    "                                    else:\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(1)\n",
    "                                        count_12 += 1\n",
    "\n",
    "                                    csv_writer.writerow(output_row)\n",
    "                                except:\n",
    "                                    continue\n",
    "                    except:\n",
    "                        print(\"empty file\")\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: RandomForest_learn()\n",
    "# Param:\n",
    "#     - None\n",
    "# Return:\n",
    "#     - model: the random forest model with default parameters (untrained).\n",
    "################################################################################################################################\n",
    "\n",
    "def RandomForest_learn():\n",
    "    model = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: training_process()\n",
    "# Param:\n",
    "#     - x_train (dataframe): the features of training data set.\n",
    "#     - y_train (dataframe): the label of training data set.\n",
    "# Return:\n",
    "#     - model_rf: the trained random forest model.\n",
    "################################################################################################################################\n",
    "\n",
    "def training_process(x_train, y_train):\n",
    "    model_rf = RandomForest_learn()\n",
    "    \n",
    "    # collect positive data for random sampling\n",
    "    positive_ids = np.where(y_train==1)[0]\n",
    "    positive_dt = x_train.iloc[positive_ids, :]\n",
    "    positive_labels = y_train.iloc[positive_ids]\n",
    "\n",
    "    for learnIter in range(20):\n",
    "        print(\"---learning iteration: \" + str(learnIter) + \"---\")\n",
    "\n",
    "        negative_ids = np.where(y_train==0)[0]\n",
    "        random_sampled_negative_ids = np.random.choice(negative_ids, size=positive_ids.shape[0], replace=False)\n",
    "\n",
    "        negative_dt = x_train.iloc[random_sampled_negative_ids, :]\n",
    "        negative_labels= y_train.iloc[random_sampled_negative_ids]\n",
    "\n",
    "        epoch_dt = np.concatenate((positive_dt, negative_dt))\n",
    "        epoch_labels = np.concatenate((positive_labels, negative_labels))\n",
    "\n",
    "        model_rf.fit(epoch_dt, epoch_labels)\n",
    "\n",
    "    return model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: calculate_confusion()\n",
    "# Param:\n",
    "#     - y_pred (dataframe): the predicted label.\n",
    "#     - y_true (dataframe): the actual label.\n",
    "# Return:\n",
    "#     - accuracy (double): accuracy of prediction\n",
    "#     - precision (double): precision of prediction\n",
    "#     - recall (double): recall of prediction\n",
    "#     - false alarm (double): false alarm of prediction\n",
    "################################################################################################################################\n",
    "\n",
    "def calculate_confusion(y_pred, y_true):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    \n",
    "    # calculate confusion matrix\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1:\n",
    "            tp += 1\n",
    "        elif y_true[i] == 1 and y_pred[i] == 0:\n",
    "            fn += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "            fp += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 0:\n",
    "            tn += 1\n",
    "            \n",
    "    print(\"tp: \" + str(tp))\n",
    "    print(\"fn: \" + str(fn))\n",
    "    print(\"fp: \" + str(fp))\n",
    "    print(\"tn: \" + str(tn))\n",
    "    \n",
    "    # accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fn + fp)\n",
    "    \n",
    "    # precision\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    # recall\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    # false alarm\n",
    "    false_alarm = fp / (fp + tn)\n",
    "    \n",
    "    return accuracy, precision, recall, false_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: test_process()\n",
    "# Param:\n",
    "#     - model: the trained random forest model.\n",
    "#     - x_train (dataframe): features in training data set\n",
    "#     - x_test (dataframe): features in test data set\n",
    "#     - y_train (dataframe): labels in training data set\n",
    "#     - y_test (dataframe): labels in test data set\n",
    "# Return:\n",
    "#     - None\n",
    "# The performance metrics are printed in the stdout.\n",
    "################################################################################################################################\n",
    "\n",
    "\n",
    "def test_process(model, x_train, x_test, y_train, y_test):\n",
    "    nb_predictedLabels = np.asarray(model.predict(x_test))\n",
    "    nb_train_predictedLabels = np.asarray(model.predict(x_train))\n",
    "\n",
    "    accuracy, precision, recall, false_alarm = calculate_confusion(nb_train_predictedLabels, np.array(y_train))\n",
    "    print(\"performance in training data set: \")\n",
    "    print(\"train accuracy is: \" + str(accuracy))\n",
    "    print(\"train precision is: \" + str(precision))\n",
    "    print(\"train recall is: \" + str(recall))\n",
    "    print(\"train false alarm is: \" + str(false_alarm))\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    accuracy, precision, recall, false_alarm = calculate_confusion(nb_predictedLabels, np.array(y_test))\n",
    "    print(\"performance in test data set: \")\n",
    "    print(\"test accuracy is: \" + str(accuracy))\n",
    "    print(\"test precision is: \" + str(precision))\n",
    "    print(\"test recall is: \" + str(recall))\n",
    "    print(\"test false alarm is: \" + str(false_alarm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Starting...\n",
      "Loading models...\n",
      "ADVANCE AMERICA CASH ADVANCE CENTERS INC_20101011-20111011.csv\n",
      "AFFILIATED MANAGERS GROUP_20090415-20100415.csv\n",
      "ALLIANCEBERNSTEIN HOLDING L.P._20121212-20131212.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 336: unexpected end of data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMERIPRISE FINANCIAL_20110120-20120120.csv\n",
      "APOLLO COMMERCIAL REAL ESTATE FINANCE INC_20150903-20160902.csv\n",
      "APOLLO GLOBAL MANAGEMENT INC_20150903-20160902.csv\n",
      "empty file\n",
      "APOLLO GLOBAL MANAGEMENT INC_20180620-20190620.csv\n",
      "empty file\n",
      "APOLLO RESIDENTIAL MORTGAGE INC_20150903-20160902.csv\n",
      "ARES MANAGEMENT CORP_20180620-20190620.csv\n",
      "empty file\n",
      "BGC PARTNERS_20070617-20080616.csv\n",
      "BLACKSTONE GROUP INC_20150506-20160505.csv\n",
      "CARLYLE GROUP INC_20120423-20130423.csv\n",
      "CASH STORE FINANCIAL SERVICES_20140206-20150206.csv\n",
      "CBOE GLOBAL MARKETS INC_20160301-20170301.csv\n",
      "CBOT HOLDINGS_20070123-20080123.csv\n",
      "CENTRAL GOLDTRUST_20150125-20160125.csv\n",
      "CME GROUP_20070123-20080123.csv\n",
      "CME GROUP_20070807-20080806.csv\n",
      "CME GROUP_20071108-20081107.csv\n",
      "CONSUMER CAPITAL GROUP_20100405-20110405.csv\n",
      "COWEN INC._20100630-20110630.csv\n",
      "DFC GLOBAL_20100412-20110412.csv\n",
      "DISCOVER FINANCIAL SERVICES_20100323-20110323.csv\n",
      "DISCOVER FINANCIAL SERVICES_20110608-20120607.csv\n",
      "DITECH HOLDING CORP_20120220-20130219.csv\n",
      "DUFF & PHELPS CORP_20120423-20130423.csv\n",
      "Edmond de Rothschild Group_20120423-20130423.csv\n",
      "ENCORE CAPITAL GROUP INC_20120613-20130613.csv\n",
      "FBR & CO_20111031-20121030.csv\n",
      "FCSTONE GROUP_2008027-20090226.csv\n",
      "FCSTONE GROUP_20081214-20091214.csv\n",
      "FIFTH STREET ASSET MANAGEMENT INC_20161017-20171017.csv\n",
      "FORTRESS INVESTMENT GROUP LLC_20140123-20150123.csv\n",
      "FORTRESS INVESTMENT GROUP LLC_20150506-20160505.csv\n",
      "FORTRESS INVESTMENT GROUP LLC_20170801-20180801.csv\n",
      "G.RESEARCH LLC_20181106-20191106.csv\n",
      "GAIN CAPITAL HOLDINGS_20111016-20121015.csv\n",
      "GAMCO INVESTORS INC. ET AL_20141204-20151204.csv\n",
      "GFI GROUP INC_20141214-20151214.csv\n",
      "empty file\n",
      "GFI GROUP INC_20150430-20160429.csv\n",
      "GIC PRIVATE LTD_20160721-20170721.csv\n",
      "GILMAN CIOCIA INC_20121021-20131021.csv\n",
      "GO SOLAR USA_20090218-20100218.csv\n",
      "GOLDMAN SACHS GROUP INC_20160818-20170818.csv\n",
      "empty file\n",
      "GOLDMAN SACHS GROUP_20101004-20111004.csv\n",
      "HENNESSY ADVISORS INC_20111031-20121030.csv\n",
      "HIGHBURY FINANCIAL_20090415-20100415.csv\n",
      "HOME LOAN SERVICING SOLUTIONS LTD_20120101-20121231.csv\n",
      "HUDSON HOLDING_20100502-20110502.csv\n",
      "INTL FCSTONE INC_20150803-20160802.csv\n",
      "INVESCO LTD_20160818-20170818.csv\n",
      "INVESCO_20090727-20100727.csv\n",
      "JANUS CAPITAL GROUP INC_20160530-20170530.csv\n",
      "JANUS HENDERSON GROUP PLC_20160530-20170530.csv\n",
      "JEFFERIES FINANCIAL GROUP INC_20150511-20160510.csv\n",
      "JEFFERIES GROUP LLC_20120301-20130301.csv\n",
      "JEFFERIES GROUP_20070422-20080421.csv\n",
      "JPMORGAN CHASE & CO_20160818-20170818.csv\n",
      "KBW INC_20120226-20130225.csv\n",
      "KKR & CO. INC_20130505-20140505.csv\n",
      "KKR & CO. INC_20131219-20141219.csv\n",
      "KKR FINANCIAL HOLDINGS LLC_20130505-20140505.csv\n",
      "KNIGHT CAPITAL GROUP LLC_20120628-20130628.csv\n",
      "KNIGHT CAPITAL GROUP_20110612-20120611.csv\n",
      "LABRANCHE &amp; CO_20090305-20100305.csv\n",
      "LABRANCHE &amp; CO_20100630-20110630.csv\n",
      "LADENBURG THALMANN FINANCIAL SERVICES_20110120-20120120.csv\n",
      "LEHMAN BROTHERS HOLDINGS_20071202-20081201.csv\n",
      "LENDINGTREE_20091223-20101223.csv\n",
      "LENDINGTREE_20110608-20120607.csv\n",
      "MICROFINANCIAL INC_20140123-20150123.csv\n",
      "MORGAN GROUP HOLDING CO_20181106-20191106.csv\n",
      "MORGAN STANLEY_20090727-20100727.csv\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "    print(\"Code Starting...\")\n",
    "    # load lda model (models are saved in the same folder as CLEAN_LDAonNews.ipynb)\n",
    "    print(\"Loading models...\")\n",
    "    cv = pickle.load(open('cv.sav', 'rb'))\n",
    "    lda = pickle.load(open('ldaM&A.sav', 'rb'))\n",
    "    \n",
    "    # define path to data file. (In local machine, this jupyter notebook is in the same level with folder \"data collection\")\n",
    "    path = \"data collection/NewData\"\n",
    "    \n",
    "    # generate feature table for the classification\n",
    "    generate_feature_table(path)\n",
    "    print(\"Finish generating features table...\")\n",
    "    \n",
    "    # start training and test phase\n",
    "    # feature_path is the path to the feature table generated above. \n",
    "    # In local machine, its in the same level with this jupyter notebook.\n",
    "    feature_path = 'ClassifyNews/NewEventTable_V1.csv'\n",
    "    df = pd.read_csv(feature_path)\n",
    "\n",
    "    x = df.iloc[:, :-4]\n",
    "    y_1 = df.iloc[:, -4]\n",
    "    y_2 = df.iloc[:, -3]\n",
    "    y_3 = df.iloc[:, -2]\n",
    "    y_4 = df.iloc[:, -1]\n",
    "    \n",
    "    # select 1/3/6/12 month: index = 1 -> 1 month; index = 2 -> 3 month; index = 3 -> 6 month; index = 4 -> 12 month.\n",
    "    index = 1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if index == 1:\n",
    "        print(\"-----Training for 1 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_1, test_size=0.3, random_state=42)\n",
    "        model = training_process(index, x_train, y_train)\n",
    "        print(\"-----Testing for 1 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "    elif index == 2:\n",
    "        print(\"-----Training for 3 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_2, test_size=0.3, random_state=42)\n",
    "        model = training_process(index, x_train, y_train)\n",
    "        print(\"-----Testing for 3 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "    elif index == 3:\n",
    "        print(\"-----Training for 6 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_3, test_size=0.3, random_state=42)\n",
    "        model = training_process(index, x_train, y_train)\n",
    "        print(\"-----Testing for 6 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "    elif index == 4:\n",
    "        print(\"-----Training for 12 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_4, test_size=0.3, random_state=42)\n",
    "        model = training_process(index, x_train, y_train)\n",
    "        print(\"-----Testing for 12 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(\"CPU running time: \" + str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
