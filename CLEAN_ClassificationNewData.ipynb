{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# packages used in this script         \n",
    "########################################\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: generate_feature_table()\n",
    "# Param:\n",
    "#     - path (str): the path to the general news data file(s).\n",
    "# Return:\n",
    "#     - None\n",
    "# Feature table is generated for the classification task\n",
    "################################################################################################################################\n",
    "\n",
    "def generate_feature_table(path, cv, lda):\n",
    "    # the generated feature table is saved in the folder \"ClassifyNews\", and the file name is \"NewEventTable_V1.csv\"\n",
    "    with open(\"ClassifyNews/NewEventTable_V1.csv\", \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',')\n",
    "        csv_writer.writerow(['id', 'company', 't1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', '1_month', '3_month', '6_month', '12_month'])\n",
    "\n",
    "        directory = path\n",
    "        for root,dirs,files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    try:\n",
    "                        print(file)\n",
    "                        data = pd.read_csv(directory + \"/\" + file, engine='python', error_bad_lines=False)\n",
    "                        data = data.to_numpy()\n",
    "\n",
    "                        event_date = (file.split(\".csv\")[0]).split('-')[-1]\n",
    "                        event_year = event_date[:4]\n",
    "                        event_month = event_date[4:6]\n",
    "                        event_day = event_date[6:8]\n",
    "                        new_event_date = str(event_year) + \"-\" + str(event_month) + \"-\" + str(event_day)\n",
    "\n",
    "                        company_name = file.split(\"_\")[0]\n",
    "\n",
    "                        for row in data:\n",
    "                            ids = row[0]\n",
    "                            available_text = True\n",
    "\n",
    "                            for i in range(len(row[1])-5):\n",
    "                                if row[1][i:i+5] == \"merge\":\n",
    "                                    available_text = False\n",
    "                                    break\n",
    "\n",
    "                                if row[1][i:i+5] == \"acqui\":\n",
    "                                    available_text = False\n",
    "                                    break\n",
    "\n",
    "                            if available_text == True:\n",
    "                                context = [row[1]]\n",
    "\n",
    "                                try:\n",
    "                                    soup = bs(row[1], \"html.parser\")\n",
    "                                    pub_date = soup.findAll('pubinfo:dates')[0]\n",
    "                                    pub_date_tag = pub_date('pubinfo:pubdate')[0]\n",
    "\n",
    "                                    day = pub_date_tag['day']\n",
    "                                    month = pub_date_tag['month']\n",
    "                                    year = pub_date_tag['year']\n",
    "\n",
    "                                    news_date = str(year) + \"-\" + str(month) + \"-\" + str(day)\n",
    "\n",
    "                                    delta_date = (datetime.strptime(new_event_date, '%Y-%m-%d') - datetime.strptime(news_date, '%Y-%m-%d')).days\n",
    "\n",
    "                                    df_temp = cv.transform(context)\n",
    "                                    prob = lda.transform(df_temp)\n",
    "\n",
    "                                    output_row = [ids, company_name]\n",
    "                                    for item in prob[0]:\n",
    "                                        output_row.append(item)\n",
    "\n",
    "                                    if delta_date < 30:\n",
    "                                        output_row.append(1)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                    elif delta_date < 90:\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(1)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                    elif delta_date < 180:\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(1)\n",
    "                                        output_row.append(0)\n",
    "                                    else:\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(0)\n",
    "                                        output_row.append(1)\n",
    "                                    \n",
    "                                    csv_writer.writerow(output_row)\n",
    "                                except:\n",
    "                                    continue\n",
    "                    except:\n",
    "                        print(\"empty file\")\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: RandomForest_learn()\n",
    "# Param:\n",
    "#     - None\n",
    "# Return:\n",
    "#     - model: the random forest model with default parameters (untrained).\n",
    "################################################################################################################################\n",
    "\n",
    "def RandomForest_learn():\n",
    "    model = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: training_process()\n",
    "# Param:\n",
    "#     - x_train (dataframe): the features of training data set.\n",
    "#     - y_train (dataframe): the label of training data set.\n",
    "# Return:\n",
    "#     - model_rf: the trained random forest model.\n",
    "################################################################################################################################\n",
    "\n",
    "def training_process(x_train, y_train):\n",
    "    model_rf = RandomForest_learn()\n",
    "    \n",
    "    # collect positive data for random sampling\n",
    "    positive_ids = np.where(y_train==1)[0]\n",
    "    positive_dt = x_train.iloc[positive_ids, :]\n",
    "    positive_labels = y_train.iloc[positive_ids]\n",
    "\n",
    "    for learnIter in range(20):\n",
    "        print(\"---learning iteration: \" + str(learnIter) + \"---\")\n",
    "\n",
    "        negative_ids = np.where(y_train==0)[0]\n",
    "        random_sampled_negative_ids = np.random.choice(negative_ids, size=positive_ids.shape[0], replace=False)\n",
    "\n",
    "        negative_dt = x_train.iloc[random_sampled_negative_ids, :]\n",
    "        negative_labels= y_train.iloc[random_sampled_negative_ids]\n",
    "\n",
    "        epoch_dt = np.concatenate((positive_dt, negative_dt))\n",
    "        epoch_labels = np.concatenate((positive_labels, negative_labels))\n",
    "\n",
    "        model_rf.fit(epoch_dt, epoch_labels)\n",
    "\n",
    "    return model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: calculate_confusion()\n",
    "# Param:\n",
    "#     - y_pred (dataframe): the predicted label.\n",
    "#     - y_true (dataframe): the actual label.\n",
    "# Return:\n",
    "#     - accuracy (double): accuracy of prediction\n",
    "#     - precision (double): precision of prediction\n",
    "#     - recall (double): recall of prediction\n",
    "#     - false alarm (double): false alarm of prediction\n",
    "################################################################################################################################\n",
    "\n",
    "def calculate_confusion(y_pred, y_true):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    \n",
    "    # calculate confusion matrix\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1:\n",
    "            tp += 1\n",
    "        elif y_true[i] == 1 and y_pred[i] == 0:\n",
    "            fn += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "            fp += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 0:\n",
    "            tn += 1\n",
    "            \n",
    "    print(\"tp: \" + str(tp))\n",
    "    print(\"fn: \" + str(fn))\n",
    "    print(\"fp: \" + str(fp))\n",
    "    print(\"tn: \" + str(tn))\n",
    "    \n",
    "    # accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fn + fp)\n",
    "    \n",
    "    # precision\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    # recall\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    # false alarm\n",
    "    false_alarm = fp / (fp + tn)\n",
    "    \n",
    "    return accuracy, precision, recall, false_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Function: test_process()\n",
    "# Param:\n",
    "#     - model: the trained random forest model.\n",
    "#     - x_train (dataframe): features in training data set\n",
    "#     - x_test (dataframe): features in test data set\n",
    "#     - y_train (dataframe): labels in training data set\n",
    "#     - y_test (dataframe): labels in test data set\n",
    "# Return:\n",
    "#     - None\n",
    "# The performance metrics are printed in the stdout.\n",
    "################################################################################################################################\n",
    "\n",
    "\n",
    "def test_process(model, x_train, x_test, y_train, y_test):\n",
    "    predictedLabels = np.asarray(model.predict(x_test))\n",
    "    train_predictedLabels = np.asarray(model.predict(x_train))\n",
    "\n",
    "    accuracy, precision, recall, false_alarm = calculate_confusion(train_predictedLabels, np.array(y_train))\n",
    "    print(\"performance in training data set: \")\n",
    "    print(\"train accuracy is: \" + str(accuracy))\n",
    "    print(\"train precision is: \" + str(precision))\n",
    "    print(\"train recall is: \" + str(recall))\n",
    "    print(\"train false alarm is: \" + str(false_alarm))\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    accuracy, precision, recall, false_alarm = calculate_confusion(predictedLabels, np.array(y_test))\n",
    "    print(\"performance in test data set: \")\n",
    "    print(\"test accuracy is: \" + str(accuracy))\n",
    "    print(\"test precision is: \" + str(precision))\n",
    "    print(\"test recall is: \" + str(recall))\n",
    "    print(\"test false alarm is: \" + str(false_alarm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Starting...\n",
      "Loading models...\n",
      "Finish generating features table...\n",
      "-----Training for 3 month data-----\n",
      "---learning iteration: 0---\n",
      "---learning iteration: 1---\n",
      "---learning iteration: 2---\n",
      "---learning iteration: 3---\n",
      "---learning iteration: 4---\n",
      "---learning iteration: 5---\n",
      "---learning iteration: 6---\n",
      "---learning iteration: 7---\n",
      "---learning iteration: 8---\n",
      "---learning iteration: 9---\n",
      "---learning iteration: 10---\n",
      "---learning iteration: 11---\n",
      "---learning iteration: 12---\n",
      "---learning iteration: 13---\n",
      "---learning iteration: 14---\n",
      "---learning iteration: 15---\n",
      "---learning iteration: 16---\n",
      "---learning iteration: 17---\n",
      "---learning iteration: 18---\n",
      "---learning iteration: 19---\n",
      "-----Testing for 3 month data-----\n",
      "tp: 13443\n",
      "fn: 5213\n",
      "fp: 26156\n",
      "tn: 49353\n",
      "performance in training data set: \n",
      "train accuracy is: 0.6668719800350449\n",
      "train precision is: 0.33947826965327405\n",
      "train recall is: 0.7205724699828473\n",
      "train false alarm is: 0.34639579387887537\n",
      "\n",
      "tp: 4425\n",
      "fn: 3578\n",
      "fp: 12030\n",
      "tn: 20324\n",
      "performance in test data set: \n",
      "test accuracy is: 0.613251728324702\n",
      "test precision is: 0.2689152233363719\n",
      "test recall is: 0.5529176558790454\n",
      "test false alarm is: 0.3718241948445324\n",
      "CPU running time: 157.17186617851257\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "    print(\"Code Starting...\")\n",
    "    # load lda model (models are saved in the same folder as CLEAN_LDAonNews.ipynb)\n",
    "    print(\"Loading models...\")\n",
    "    cv = pickle.load(open('cv.sav', 'rb'))\n",
    "    lda = pickle.load(open('ldaM&A.sav', 'rb'))\n",
    "    \n",
    "    # define path to data file. (In local machine, this jupyter notebook is in the same level with folder \"data collection\")\n",
    "    path = \"data collection/NewData\"\n",
    "    \n",
    "    # generate feature table for the classification\n",
    "    ######################################################################################################################\n",
    "    # IMPORTANT HERE!!!!!                                                                                                #\n",
    "    # YOU WANT TO COMMENT THIS PART OUT after the first run... You don't want to generate feature table again unless you #\n",
    "    # have new input data.                                                                                               #\n",
    "    ######################################################################################################################\n",
    "    generate_feature_table(path, cv, lda)\n",
    "    print(\"Finish generating features table...\")\n",
    "    \n",
    "    # start training and test phase\n",
    "    # feature_path is the path to the feature table generated above. \n",
    "    # In local machine, its in the same level with this jupyter notebook.\n",
    "    feature_path = 'ClassifyNews/NewEventTable_V1.csv'\n",
    "    df = pd.read_csv(feature_path)\n",
    "\n",
    "    x = df.iloc[:, 2:-4]\n",
    "    y_1 = df.iloc[:, -4]\n",
    "    y_2 = df.iloc[:, -3]\n",
    "    y_3 = df.iloc[:, -2]\n",
    "    y_4 = df.iloc[:, -1]\n",
    "    \n",
    "    # select 1/3/6/12 month: index = 1 -> 1 month; index = 2 -> 3 month; index = 3 -> 6 month; index = 4 -> 12 month.\n",
    "    index = 2\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if index == 1:\n",
    "        print(\"-----Training for 1 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_1, test_size=0.3, random_state=42)\n",
    "        model = training_process(x_train, y_train)\n",
    "        print(\"-----Testing for 1 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "    elif index == 2:\n",
    "        print(\"-----Training for 3 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_2, test_size=0.3, random_state=42)\n",
    "        model = training_process(x_train, y_train)\n",
    "        print(\"-----Testing for 3 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "    elif index == 3:\n",
    "        print(\"-----Training for 6 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_3, test_size=0.3, random_state=42)\n",
    "        model = training_process(x_train, y_train)\n",
    "        print(\"-----Testing for 6 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "    elif index == 4:\n",
    "        print(\"-----Training for 12 month data-----\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y_4, test_size=0.3, random_state=42)\n",
    "        model = training_process(x_train, y_train)\n",
    "        print(\"-----Testing for 12 month data-----\")\n",
    "        test_process(model, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(\"CPU running time: \" + str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
